{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'ProductId', 'ProductPrice', 'LocationId',\n",
       "       'SalesVolume', 'SalesValue', 'ItemName', 'ProductType',\n",
       "       'ProductSubCategory', 'ProductCategory', 'Department', 'LocationType',\n",
       "       'LocationPincode', 'LocationAddress', 'City', 'State', 'Country',\n",
       "       'Month', 'Week', 'Quarter', 'WeekOfYear', 'Year', 'RowNumber',\n",
       "       'SupplierId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_group_by_grain(fileName:str, time:str=\"Month\", product:str=\"\", location:str=\"\") -> tuple:\n",
    "    df = pd.read_csv(fileName)\n",
    "    \n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    group_columns = []\n",
    "\n",
    "    if(time == 'Month'):\n",
    "        group_columns.append('Year')\n",
    "    elif(time == 'Quater'):\n",
    "        group_columns.extend(['Year','Month'])\n",
    "    elif(time == 'Week'):\n",
    "        group_columns.extend(['Year','Month','Quarter'])\n",
    "    \n",
    "    group_columns.append(time)\n",
    "\n",
    "    if product:\n",
    "        group_columns.append(product)\n",
    "    if location:\n",
    "        group_columns.append(location)\n",
    "    \n",
    "    grouped_df = df.groupby(group_columns).agg({\n",
    "        'SalesVolume': 'sum',  \n",
    "    }).reset_index()\n",
    "    grouped_df['Key'] = grouped_df.apply(lambda row: f\"{row[product]}_{row[location]}\", axis=1)  \n",
    "    distinct_keys = grouped_df['Key'].unique().tolist()\n",
    "    return (grouped_df,group_columns,distinct_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series_data(df, learning_time, skip_period, horizon,group_cols, distinct_keys):\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    for key in distinct_keys:\n",
    "    \n",
    "        filtered_df = df[df['Key'] == key].copy()\n",
    "        filtered_df.sort_values(by=group_cols, inplace=True)\n",
    "        filtered_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        for i in range(1, learning_time + 1):\n",
    "            column_name_b = f\"SalesVolume_lag_{i}\"\n",
    "            filtered_df[column_name_b] = filtered_df['SalesVolume'].shift(i)\n",
    "    \n",
    "        for i in range(1, horizon + 1):\n",
    "            column_name_b = f\"skip_period_{skip_period}_horizon_{i}_SalesVolume_lead\"\n",
    "            filtered_df[column_name_b] = filtered_df['SalesVolume'].shift(-(skip_period + i))\n",
    "        \n",
    "        filtered_df.dropna(inplace=True)\n",
    "        filtered_dfs.append(filtered_df)\n",
    "    concatenated_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "    return concatenated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "time_column = 'Month'  \n",
    "product_column = 'ProductType'  \n",
    "location_column = 'City'  \n",
    "file_name = 'data.csv'\n",
    "result_df,group_columns,distinct_keys = transform_and_group_by_grain(file_name,time_column, product_column, location_column)\n",
    "print(len(distinct_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>ProductType</th>\n",
       "      <th>City</th>\n",
       "      <th>SalesVolume</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>966151</td>\n",
       "      <td>Apparel_Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>703495</td>\n",
       "      <td>Apparel_Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>841488</td>\n",
       "      <td>Apparel_Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>792268</td>\n",
       "      <td>Apparel_Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>839441</td>\n",
       "      <td>Apparel_Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Waste Disposal</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>133960</td>\n",
       "      <td>Waste Disposal_Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Waste Disposal</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>160236</td>\n",
       "      <td>Waste Disposal_Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8061</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Waste Disposal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>150870</td>\n",
       "      <td>Waste Disposal_Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Waste Disposal</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>159847</td>\n",
       "      <td>Waste Disposal_Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Waste Disposal</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>141265</td>\n",
       "      <td>Waste Disposal_New Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8064 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month     ProductType       City  SalesVolume   \n",
       "0     2019      1         Apparel  Bangalore       966151  \\\n",
       "1     2019      1         Apparel    Chennai       703495   \n",
       "2     2019      1         Apparel  Hyderabad       841488   \n",
       "3     2019      1         Apparel    Kolkata       792268   \n",
       "4     2019      1         Apparel     Mumbai       839441   \n",
       "...    ...    ...             ...        ...          ...   \n",
       "8059  2022     12  Waste Disposal    Chennai       133960   \n",
       "8060  2022     12  Waste Disposal  Hyderabad       160236   \n",
       "8061  2022     12  Waste Disposal    Kolkata       150870   \n",
       "8062  2022     12  Waste Disposal     Mumbai       159847   \n",
       "8063  2022     12  Waste Disposal  New Delhi       141265   \n",
       "\n",
       "                           Key  \n",
       "0            Apparel_Bangalore  \n",
       "1              Apparel_Chennai  \n",
       "2            Apparel_Hyderabad  \n",
       "3              Apparel_Kolkata  \n",
       "4               Apparel_Mumbai  \n",
       "...                        ...  \n",
       "8059    Waste Disposal_Chennai  \n",
       "8060  Waste Disposal_Hyderabad  \n",
       "8061    Waste Disposal_Kolkata  \n",
       "8062     Waste Disposal_Mumbai  \n",
       "8063  Waste Disposal_New Delhi  \n",
       "\n",
       "[8064 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_time = 3\n",
    "skip_period = 3\n",
    "horizon = 4\n",
    "prepared_df = prepare_time_series_data(result_df, learning_time, skip_period, horizon,group_columns,distinct_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "horizon = 3\n",
    "for key in distinct_keys:\n",
    "    models = []\n",
    "    for i in range(1,horizon+1):\n",
    "        rf_model = RandomForestRegressor()\n",
    "        models.append(rf_model)\n",
    "    \n",
    "    model_dict[key] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df,time_group_col,models,horizon):\n",
    "    X_lagged_list_train = df.filter(regex='SalesVolume_lag_').values\n",
    "    X_additional_list_train = df[time_group_col].values\n",
    "    X_train = np.column_stack((X_lagged_list_train, X_additional_list_train))\n",
    "\n",
    "    y_columns = [f\"skip_period_{skip_period}_horizon_{h}_SalesVolume_lead\" for h in range(1, horizon+1)]\n",
    "    Y_train = df[y_columns].values\n",
    "    for i in range(horizon):\n",
    "        y_horizon = Y_train[:, i]\n",
    "        models[i].fit(X_train,y_horizon.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df_test,time_group_col,models,horizon,predictions_df_dict,key):\n",
    "    # df_test = df.iloc[split_index:]\n",
    "    predictions_df = pd.DataFrame()\n",
    "    X_lagged_list_test = df_test.filter(regex='SalesVolume_lag_').values\n",
    "    X_additional_list_test = df_test[time_group_col].values\n",
    "    X_test = np.column_stack((X_lagged_list_test, X_additional_list_test))\n",
    "\n",
    "    y_columns = [f\"skip_period_{skip_period}_horizon_{h}_SalesVolume_lead\" for h in range(1, horizon+1)]\n",
    "    Y_test = df_test[y_columns].values\n",
    "    predictions_df[time_group_col] = df_test[time_group_col]\n",
    "\n",
    "    for i in range(horizon):\n",
    "        predictions = models[i].predict(X_test)\n",
    "        predictions_df[f\"Horizon_{i+1}_Predictions\"] = predictions\n",
    "        y_horizon = Y_test[:, i]\n",
    "        predictions_df[f\"Horizon_{i+1}_Actuals\"] = y_horizon\n",
    "\n",
    "    predictions_df_dict[key].append(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_set not possible training testing through default mode\n"
     ]
    }
   ],
   "source": [
    "predictions_df_dict = {}\n",
    "        \n",
    "def train_test_split_fun1(minimum_test_cases,minimum_train_cases,minimum_set,distinct_keys):\n",
    "    for key in distinct_keys:\n",
    "        filtered_df = prepared_df[prepared_df['Key'] == key]\n",
    "        increase = (len(filtered_df)-minimum_test_cases-minimum_train_cases)//minimum_set\n",
    "        if(minimum_train_cases + increase * minimum_set + minimum_test_cases > len(filtered_df) or increase == 0):\n",
    "            print(\"minimum_set not possible training testing through default mode\")\n",
    "            minimum_train_cases = int(len(filtered_df) * 0.5)\n",
    "            minimum_test_cases = int(len(filtered_df) * 0.1)\n",
    "            increase  = 2\n",
    "        # print(\"increase\",increase)\n",
    "        print(filtered_df)\n",
    "        predictions_df_dict[key] = []\n",
    "        for i in range(minimum_train_cases,len(filtered_df)-minimum_test_cases+1,increase):\n",
    "            df_train = filtered_df.iloc[:i]\n",
    "            train_model(df_train,['Month', 'Year'],model_dict[key],3)\n",
    "            # df_test = filtered_df.iloc[i:]\n",
    "            # test_model(df_test,['Month', 'Year'],model_dict[key],3,predictions_df_dict,key)\n",
    "\n",
    "\n",
    "train_test_split_fun1(15,20,4,distinct_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Horizon_1_Predictions</th>\n",
       "      <th>Horizon_1_Actuals</th>\n",
       "      <th>Horizon_2_Predictions</th>\n",
       "      <th>Horizon_2_Actuals</th>\n",
       "      <th>Horizon_3_Predictions</th>\n",
       "      <th>Horizon_3_Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1409990.56</td>\n",
       "      <td>1446892.0</td>\n",
       "      <td>1793760.76</td>\n",
       "      <td>1772994.0</td>\n",
       "      <td>2132555.27</td>\n",
       "      <td>2210892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>1777424.90</td>\n",
       "      <td>1772994.0</td>\n",
       "      <td>2092594.44</td>\n",
       "      <td>2210892.0</td>\n",
       "      <td>1807233.29</td>\n",
       "      <td>1805908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>2063789.21</td>\n",
       "      <td>2210892.0</td>\n",
       "      <td>1802100.71</td>\n",
       "      <td>1805908.0</td>\n",
       "      <td>1094568.74</td>\n",
       "      <td>1024227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>1780864.41</td>\n",
       "      <td>1805908.0</td>\n",
       "      <td>1110981.44</td>\n",
       "      <td>1024227.0</td>\n",
       "      <td>1050585.44</td>\n",
       "      <td>1010870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>1130391.15</td>\n",
       "      <td>1024227.0</td>\n",
       "      <td>1029186.70</td>\n",
       "      <td>1010870.0</td>\n",
       "      <td>1248703.49</td>\n",
       "      <td>1286658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1009882.45</td>\n",
       "      <td>1010870.0</td>\n",
       "      <td>1226351.05</td>\n",
       "      <td>1286658.0</td>\n",
       "      <td>932908.77</td>\n",
       "      <td>930758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>1220906.89</td>\n",
       "      <td>1286658.0</td>\n",
       "      <td>941329.69</td>\n",
       "      <td>930758.0</td>\n",
       "      <td>821327.79</td>\n",
       "      <td>784162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>960800.99</td>\n",
       "      <td>930758.0</td>\n",
       "      <td>829919.60</td>\n",
       "      <td>784162.0</td>\n",
       "      <td>940687.12</td>\n",
       "      <td>972979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>810129.60</td>\n",
       "      <td>784162.0</td>\n",
       "      <td>972242.18</td>\n",
       "      <td>972979.0</td>\n",
       "      <td>1400238.53</td>\n",
       "      <td>1410579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>975242.05</td>\n",
       "      <td>972979.0</td>\n",
       "      <td>1406286.07</td>\n",
       "      <td>1410579.0</td>\n",
       "      <td>1711288.39</td>\n",
       "      <td>1801547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>1442432.86</td>\n",
       "      <td>1410579.0</td>\n",
       "      <td>1535239.64</td>\n",
       "      <td>1801547.0</td>\n",
       "      <td>1496771.39</td>\n",
       "      <td>1408094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>1649292.77</td>\n",
       "      <td>1801547.0</td>\n",
       "      <td>1217615.50</td>\n",
       "      <td>1408094.0</td>\n",
       "      <td>1704223.44</td>\n",
       "      <td>1762730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>1244453.17</td>\n",
       "      <td>1408094.0</td>\n",
       "      <td>1728692.29</td>\n",
       "      <td>1762730.0</td>\n",
       "      <td>2224747.16</td>\n",
       "      <td>2181694.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Year  Horizon_1_Predictions  Horizon_1_Actuals   \n",
       "25      5  2021             1409990.56          1446892.0  \\\n",
       "26      6  2021             1777424.90          1772994.0   \n",
       "27      7  2021             2063789.21          2210892.0   \n",
       "28      8  2021             1780864.41          1805908.0   \n",
       "29      9  2021             1130391.15          1024227.0   \n",
       "30     10  2021             1009882.45          1010870.0   \n",
       "31     11  2021             1220906.89          1286658.0   \n",
       "32     12  2021              960800.99           930758.0   \n",
       "33      1  2022              810129.60           784162.0   \n",
       "34      2  2022              975242.05           972979.0   \n",
       "35      3  2022             1442432.86          1410579.0   \n",
       "36      4  2022             1649292.77          1801547.0   \n",
       "37      5  2022             1244453.17          1408094.0   \n",
       "\n",
       "    Horizon_2_Predictions  Horizon_2_Actuals  Horizon_3_Predictions   \n",
       "25             1793760.76          1772994.0             2132555.27  \\\n",
       "26             2092594.44          2210892.0             1807233.29   \n",
       "27             1802100.71          1805908.0             1094568.74   \n",
       "28             1110981.44          1024227.0             1050585.44   \n",
       "29             1029186.70          1010870.0             1248703.49   \n",
       "30             1226351.05          1286658.0              932908.77   \n",
       "31              941329.69           930758.0              821327.79   \n",
       "32              829919.60           784162.0              940687.12   \n",
       "33              972242.18           972979.0             1400238.53   \n",
       "34             1406286.07          1410579.0             1711288.39   \n",
       "35             1535239.64          1801547.0             1496771.39   \n",
       "36             1217615.50          1408094.0             1704223.44   \n",
       "37             1728692.29          1762730.0             2224747.16   \n",
       "\n",
       "    Horizon_3_Actuals  \n",
       "25          2210892.0  \n",
       "26          1805908.0  \n",
       "27          1024227.0  \n",
       "28          1010870.0  \n",
       "29          1286658.0  \n",
       "30           930758.0  \n",
       "31           784162.0  \n",
       "32           972979.0  \n",
       "33          1410579.0  \n",
       "34          1801547.0  \n",
       "35          1408094.0  \n",
       "36          1762730.0  \n",
       "37          2181694.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df_dict['Apparel_Bangalore'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(horizon,prediction_df):\n",
    "    predictions_col = []\n",
    "    actuals_col = []\n",
    "    for i in range(horizon):  # for Horizon 1 to Horizon 3\n",
    "        predictions_col_ele = f'Horizon_{i+1}_Predictions'\n",
    "        predictions_col.append(predictions_col_ele)\n",
    "        actuals_col_ele = f'Horizon_{i+1}_Actuals'\n",
    "        actuals_col.append(actuals_col_ele)\n",
    "\n",
    "    actuals_col_sum = prediction_df[actuals_col].sum()\n",
    "    predictions_col_sum = prediction_df[predictions_col].sum() \n",
    "    WMAPES = []\n",
    "    for i in range(0, horizon):\n",
    "        WMAPE = (abs(actuals_col_sum[i] - predictions_col_sum[i])/actuals_col_sum[i])*100\n",
    "        WMAPES.append(WMAPE)\n",
    "    return WMAPES\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in distinct_keys:\n",
    "    accuracy = [0]*horizon\n",
    "    for df in predictions_df_dict[key]:\n",
    "        temp = metrics(horizon,df)\n",
    "        for i in range(horizon):\n",
    "            accuracy[i] = accuracy[i] + temp[i] \n",
    "    accuracy = [i/horizon for i in accuracy] \n",
    "    model_dict[key] = [model_dict[key],accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor()],\n",
       " [7.011474391191105, 14.094185717944042, 1.9612783446305404]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['Apparel_Bangalore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start  = 4\n",
    "end = 5\n",
    "horizon_temp = end - start + 1\n",
    "def train_test_split_fun2(start,end,time_column):\n",
    "    for key in distinct_keys:\n",
    "        filtered_df = prepared_df[prepared_df['Key'] == key]\n",
    "        increase = (len(filtered_df)-minimum_test_cases-minimum_train_cases)//minimum_set\n",
    "        if(minimum_train_cases + increase * minimum_set + minimum_test_cases > len(filtered_df) or increase == 0):\n",
    "            print(\"minimum_set not possible training testing through default mode\")\n",
    "            minimum_train_cases = int(len(filtered_df) * 0.5)\n",
    "            minimum_test_cases = int(len(filtered_df) * 0.1)\n",
    "            increase  = 2\n",
    "        # print(\"increase\",increase)\n",
    "        print(filtered_df)\n",
    "        predictions_df_dict[key] = []\n",
    "        for i in range(minimum_train_cases,len(filtered_df)-minimum_test_cases+1,increase):\n",
    "            df_train = filtered_df.iloc[:i]\n",
    "            train_model(df_train,['Month', 'Year'],model_dict[key],3)\n",
    "            # df_test = filtered_df.iloc[i:]\n",
    "            # test_model(df_test,['Month', 'Year'],model_dict[key],3,predictions_df_dict,key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
